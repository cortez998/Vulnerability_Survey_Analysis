import os
import re
import statistics

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt  

from datetime import datetime 
from matplotlib import cm

from sklearn.linear_model import LinearRegression 
from sklearn.metrics import r2_score
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import OrdinalEncoder 
from sklearn.feature_selection import chi2, f_classif, RFE 
from sklearn.decomposition import PCA 

wave_1 = pd.read_csv("C:/Users/marco/OneDrive/Desktop/QDC/Challenge/data/final cleaning/brc-vulnerability-survey-wave-1_secondcleaning.csv", encoding='mac_roman')
wave_2 = pd.read_csv("C:/Users/marco/OneDrive/Desktop/QDC/Challenge/data/final cleaning/brc-vulnerability-survey-wave-2_final_cleaning.csv", encoding='mac_roman')

#function to get summary
def summarize_frame(df: pd.DataFrame) -> pd.DataFrame:
    dataframe = pd.DataFrame()
    
    dataframe['dtype'] = df.dtypes
    
    dataframe['first_value'] = df.iloc[0]
    
    nan_perc = []
    for i in df.columns:
        nan_count = df[i].isna().sum()
        nan_perc.append(nan_count/len(df[i]))
    dataframe['nan_perc'] = nan_perc
    
    unique_count = []
    for i in df.columns:
        unique_count.append(len(df[i].dropna().unique()))
    dataframe['unique_count'] = unique_count
    
    dataframe['mean'] = df.mean()
    
    dataframe['st_dev'] = df.std()
    
    return dataframe


summary_wave_1 = summarize_frame(wave_1)
summary_wave_2 = summarize_frame(wave_2)

print(wave_1.duplicated().any())
print(wave_2.duplicated().any())

